{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CIL of pix2pix.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "qmkj-80IHxnd",
        "colab": {}
      },
      "source": [
        "# basis is the official pix2pix tutorial on the tensorflow website"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ05GVPef3_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = \"maps1800\" # original, retiled, maps1800"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h0oMzIX3pPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "#print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmbsON3i3sKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_xnMOsbqHz61"
      },
      "source": [
        "# Pix2Pix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "## Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YfIk2es3hJEd",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wifwThPoEj7e",
        "colab": {}
      },
      "source": [
        "!pip install -U tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kn-k8kTXuAlv",
        "colab": {}
      },
      "source": [
        "PATH = \"/home/jonathan/CIL-street/data/\"+dataset+\"/all/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7O5i_5VtaJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2CbTEt448b4R",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 512 # should not make a difference\n",
        "BATCH_SIZE = 1 # increasing batch size did not speed up training significantly and caused OOM errors\n",
        "IMG_WIDTH = 512\n",
        "IMG_HEIGHT = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aO9ZAGH5K3SY",
        "colab": {}
      },
      "source": [
        "def load(image_file):\n",
        "  print(\"load\")\n",
        "  image = tf.io.read_file(image_file)\n",
        "  image = tf.image.decode_jpeg(image, channels=3) # need to be careful, apparently some images are saved with 1 channel and some with 3 channels\n",
        "  input_image = tf.cast(image, tf.float32)\n",
        "  return input_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4OLHMpsQ5aOv",
        "colab": {}
      },
      "source": [
        "PATH_original = \"/home/jonathan/CIL-street/data/original/training/\"\n",
        "path = PATH_original+'images/satImage_002.png'\n",
        "path_gt = PATH_original+'groundtruth/satImage_002.png'\n",
        "inp = tf.image.resize(load(path), (512, 512))\n",
        "re = tf.image.resize(load(path_gt), (512, 512))\n",
        "\n",
        "# casting to int for matplotlib to show the image\n",
        "plt.figure()\n",
        "plt.imshow(inp/255.0)\n",
        "plt.figure()\n",
        "plt.imshow(re/255.0, cmap='Greys_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rwwYQpu9FzDu",
        "colab": {}
      },
      "source": [
        "def resize(input_image, real_image, height, width):\n",
        "  input_image = tf.image.resize(input_image, [height, width],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  real_image = tf.image.resize(real_image, [height, width],\n",
        "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "  return input_image, real_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yn3IwqhiIszt",
        "colab": {}
      },
      "source": [
        "def random_crop(input_image, real_image):\n",
        "  stacked_image = tf.stack([input_image, real_image], axis=0)\n",
        "  cropped_image = tf.image.random_crop(\n",
        "      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "\n",
        "  return cropped_image[0], cropped_image[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "muhR2cgbLKWW",
        "colab": {}
      },
      "source": [
        "# normalizing the images to [-1, 1]\n",
        "\n",
        "def normalize(input_image, real_image):\n",
        "  input_image = (input_image / 127.5) - 1\n",
        "  real_image = (real_image / 127.5) - 1\n",
        "\n",
        "  return input_image, real_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fVQOjcPVLrUc",
        "colab": {}
      },
      "source": [
        "@tf.function()\n",
        "def random_jitter(input_image, real_image):\n",
        "\n",
        "  rot = tf.random.uniform(\n",
        "    (), minval=0, maxval=4, dtype=tf.dtypes.int32\n",
        "    )\n",
        "  input_image = tf.image.rot90(input_image, k = rot)\n",
        "  real_image = tf.image.rot90(real_image, k = rot)\n",
        "\n",
        "  input_image, real_image = resize(input_image, real_image, 286*2, 286*2)\n",
        "  input_image, real_image = random_crop(input_image, real_image)\n",
        "\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    # random mirroring\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    real_image = tf.image.flip_left_right(real_image)\n",
        "\n",
        "  return input_image, real_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wfAQbzy799UV"
      },
      "source": [
        "As you can see in the images below\n",
        "that they are going through random jittering\n",
        "Random jittering as described in the paper is to\n",
        "\n",
        "1. Resize an image to bigger height and width\n",
        "2. Randomly crop to the target size\n",
        "3. Randomly flip the image horizontally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n0OGdi6D92kM",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "for i in range(4):\n",
        "  rj_inp, rj_re = random_jitter(inp, re)\n",
        "  plt.subplot(2, 2, i+1)\n",
        "  plt.imshow(rj_inp/255.0)\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tyaP4hLJ8b4W",
        "colab": {}
      },
      "source": [
        "def load_image_train(image_file, image_file_gt):\n",
        "  print(image_file)\n",
        "  input_image = load(image_file)\n",
        "  img_gray = load(image_file_gt)\n",
        "  print(img_gray.shape)\n",
        "  real_image = tf.image.grayscale_to_rgb(img_gray) if (img_gray.shape[2] == 1) else img_gray\n",
        "  input_image, real_image = random_jitter(input_image, real_image)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "  real_image = tf.image.rgb_to_grayscale(real_image)\n",
        "  \n",
        "  return input_image, real_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VB3Z6D_zKSru",
        "colab": {}
      },
      "source": [
        "def load_image_test(image_file, image_file_gt):\n",
        "  print(\"load image test\")\n",
        "  print(image_file)\n",
        "  input_image = load(image_file)\n",
        "  img_gray = load(image_file_gt)\n",
        "  print(img_gray.shape)\n",
        "  real_image = tf.image.grayscale_to_rgb(img_gray) if (img_gray.shape[2] == 1) else img_gray\n",
        "  input_image, real_image = resize(input_image, real_image,\n",
        "                                   IMG_HEIGHT, IMG_WIDTH)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "  real_image = tf.image.rgb_to_grayscale(real_image)\n",
        "\n",
        "  return input_image, real_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PIGN6ouoQxt3"
      },
      "source": [
        "## Input Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SQHmYSmk8b4b",
        "colab": {}
      },
      "source": [
        "print(PATH)\n",
        "full_dataset_images = tf.data.Dataset.list_files(PATH+'images/*.png', shuffle=False)\n",
        "full_dataset_gt = tf.data.Dataset.list_files(PATH+'groundtruth/*.png',shuffle=False)\n",
        "full_dataset = tf.data.Dataset.zip((full_dataset_images, full_dataset_gt))\n",
        "full_dataset = full_dataset.shuffle(BUFFER_SIZE)\n",
        "print(sum(1 for _ in full_dataset))\n",
        "\n",
        "train_dataset = full_dataset.take(1800) \n",
        "train_dataset = full_dataset.map(load_image_train,\n",
        "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = full_dataset.skip(1800)\n",
        "test_dataset = test_dataset.map(load_image_test)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MS9J0yA58b4g",
        "colab": {}
      },
      "source": [
        "'''TEST_PATH = '/home/jonathan/CIL-street/data/original/validation/'\n",
        "test_dataset_images = tf.data.Dataset.list_files(TEST_PATH+'images/*.png', shuffle=False)\n",
        "test_dataset_gt = tf.data.Dataset.list_files(TEST_PATH+'groundtruth/*.png',shuffle=False)\n",
        "test_dataset = tf.data.Dataset.zip((test_dataset_images, test_dataset_gt))\n",
        "print(test_dataset)\n",
        "print(sum(1 for _ in test_dataset))\n",
        "test_dataset = test_dataset.map(load_image_test)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "## Build the Generator\n",
        "  * The architecture of generator is a modified U-Net.\n",
        "  * Each block in the encoder is (Conv -> Batchnorm -> Leaky ReLU)\n",
        "  * Each block in the decoder is (Transposed Conv -> Batchnorm -> Dropout(applied to the first 3 blocks) -> ReLU)\n",
        "  * There are skip connections between the encoder and decoder (as in U-Net).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tqqvWxlw8b4l",
        "colab": {}
      },
      "source": [
        "OUTPUT_CHANNELS = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3R09ATE_SH9P",
        "colab": {}
      },
      "source": [
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "  if apply_batchnorm:\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  result.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a6_uCZCppTh7",
        "colab": {}
      },
      "source": [
        "down_model = downsample(3, 4)\n",
        "down_result = down_model(tf.expand_dims(inp, 0))\n",
        "print (down_result.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nhgDsHClSQzP",
        "colab": {}
      },
      "source": [
        "def upsample(filters, size, apply_dropout=False):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer=initializer,\n",
        "                                    use_bias=False))\n",
        "\n",
        "  result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  if apply_dropout:\n",
        "      result.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  result.add(tf.keras.layers.ReLU())\n",
        "\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mz-ahSdsq0Oc",
        "colab": {}
      },
      "source": [
        "up_model = upsample(3, 4)\n",
        "up_result = up_model(down_result)\n",
        "print (up_result.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bngq_YWkf6ZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U image-classifiers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from classification_models.tfkeras import Classifiers\n",
        "\n",
        "def RoadNet(backbone_name='seresnext50', input_shape=(None, None, 3), encoder_weights='imagenet',\n",
        "            encoder_freeze=False, predict_distance=False, predict_contour=False, aspp=False, se=False):\n",
        "    \"\"\"\n",
        "    Encoder-decoder based architecture for road segmentation in aerial images.\n",
        "    :param backbone_name: name of the backbone network. Supported backbones are ResNet50, ResNet101, SEResNet50,\n",
        "                          SEResNet101, ResNeXt50, ResNeXt101, SEResNeXt50 and  SEResNeXt101.\n",
        "    :param input_shape: input shape, where the first two dimensions need to be a multiple of 16.\n",
        "    :param encoder_weights: name of dataset for which to load weights. Only ImageNet is supported.\n",
        "    :param encoder_freeze: freezes the weights in the backbone save from batch normalization layers\n",
        "    :param predict_distance: if true, adds an additional output predicting the distance map of the road mask\n",
        "    :param predict_contour: if true, adds an additional output predicting the contour of the road mask\n",
        "    :param aspp: if true, the encoder output is passed through an ASPP module. More info at\n",
        "                 http://liangchiehchen.com/projects/DeepLab.html\n",
        "    :param se: if true, enables Squeeze and Excitation on the decoder convolutional blocks. More info at\n",
        "               https://arxiv.org/abs/1709.01507\n",
        "    :return: a tf.keras instance of the model\n",
        "    \"\"\"\n",
        "\n",
        "    decoder_filters = (256, 128, 64, 32, 16)\n",
        "    n_blocks = len(decoder_filters)\n",
        "    skip_layers_dict = {'seresnext50': (1078, 584, 254, 4), 'seresnext101': (2472, 584, 254, 4),\n",
        "                        'seresnet101': (552, 136, 62, 4), 'seresnet50': (246, 136, 62, 4),\n",
        "                        'resnext50': ('stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0'),\n",
        "                        'resnext101': ('stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0'),\n",
        "                        'resnet50': ('stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0'),\n",
        "                        'resnet101': ('stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0')}\n",
        "    skip_layers = skip_layers_dict[backbone_name]\n",
        "\n",
        "    # load backbone network from external library\n",
        "    backbone_fn, _ = Classifiers.get(backbone_name)\n",
        "    backbone = backbone_fn(input_shape=input_shape, weights=encoder_weights, include_top=False)\n",
        "    skips = ([backbone.get_layer(name=i).output if isinstance(i, str)\n",
        "              else backbone.get_layer(index=i).output for i in skip_layers])\n",
        "\n",
        "    x = backbone.output\n",
        "\n",
        "    # build ASPP if requested\n",
        "    if aspp:\n",
        "        b0 = GlobalAveragePooling2D()(x)\n",
        "        b0 = Lambda(lambda x: tf.keras.backend.expand_dims(x, 1))(b0)\n",
        "        b0 = Lambda(lambda x: tf.keras.backend.expand_dims(x, 1))(b0)\n",
        "        b0 = Conv2D(256, (1, 1), padding='same', use_bias=False, name='aspp_pooling')(b0)\n",
        "        b0 = BatchNormalization(name='aspp_pooling_bn')(b0)\n",
        "        b0 = Activation('relu', name='aspp_pooling_relu')(b0)\n",
        "        b0 = Lambda(lambda x : tf.image.resize(x, (12, 12)))(b0)\n",
        "\n",
        "        b1 = Conv2D(256, 1, padding='same', dilation_rate=(1, 1), kernel_initializer='he_normal', name='aspp_b1_conv')(x)\n",
        "        b1 = BatchNormalization(axis=3, name='aspp_b1_bn')(b1)\n",
        "        b1 = Activation('relu', name='aspp_b1_relu')(b1)\n",
        "        b2 = Conv2D(256, 3, padding='same', dilation_rate=(3, 3), kernel_initializer='he_normal', name='aspp_b2_conv')(x)\n",
        "        b2 = BatchNormalization(axis=3, name='aspp_b2_bn')(b2)\n",
        "        b2 = Activation('relu', name='aspp_b2_relu')(b2)\n",
        "        b3 = Conv2D(256, 3, padding='same', dilation_rate=(6, 6), kernel_initializer='he_normal', name='aspp_b3_conv')(x)\n",
        "        b3 = BatchNormalization(axis=3, name='aspp_b3_bn')(b3)\n",
        "        b3 = Activation('relu', name='aspp_b3_relu')(b3)\n",
        "\n",
        "        x = Concatenate(axis=3, name='aspp_concat')([b0, b1, b2, b3])\n",
        "        x = Conv2D(256, (1, 1), padding='same', use_bias=False, name='aspp_concat_conv')(x)\n",
        "        x = BatchNormalization(axis=3, name='aspp_concat_bn')(x)\n",
        "        x = Activation('relu', name='aspp_concat_relu')(x)\n",
        "\n",
        "    # create the decoder blocks sequentially\n",
        "    for i in range(n_blocks):\n",
        "\n",
        "        filters = decoder_filters[i]\n",
        "\n",
        "        x = UpSampling2D(size=2, name='decoder_stage{}_upsample'.format(i))(x)\n",
        "        # skip connection\n",
        "        if i < len(skips):\n",
        "            x = Concatenate(axis=3, name='decoder_stage{}_concat'.format(i))([x, skips[i]])\n",
        "\n",
        "        x = Conv2D(filters=filters, kernel_size=3, padding='same', use_bias=False, kernel_initializer='he_uniform', name='decoder_stage{}a_conv'.format(i))(x)\n",
        "        x = BatchNormalization(axis=3, name='decoder_stage{}a_bn'.format(i))(x)\n",
        "        x = Activation('relu', name='decoder_stage{}a_activation'.format(i))(x)\n",
        "\n",
        "        # Squeeze and Excitation on the first convolution\n",
        "        if se:\n",
        "            w = GlobalAveragePooling2D(name='decoder_stage{}a_se_avgpool'.format(i))(x)\n",
        "            w = Dense(filters // 8, activation='relu', name='decoder_stage{}a_se_dense1'.format(i))(w)\n",
        "            w = Dense(filters, activation='sigmoid', name='decoder_stage{}a_se_dense2'.format(i))(w)\n",
        "            x = Multiply(name='decoder_stage{}a_se_mult'.format(i))([x, w])\n",
        "\n",
        "        x = Conv2D(filters=filters, kernel_size=3, padding='same', use_bias=False, kernel_initializer='he_uniform', name='decoder_stage{}b_conv'.format(i))(x)\n",
        "        x = BatchNormalization(axis=3, name='decoder_stage{}b_bn'.format(i))(x)\n",
        "        x = Activation('relu', name='decoder_stage{}b_activation'.format(i))(x)\n",
        "\n",
        "        # Squeeze and Excitation on the second convolution\n",
        "        if se:\n",
        "            w = GlobalAveragePooling2D(name='decoder_stage{}b_se_avgpool'.format(i))(x)\n",
        "            w = Dense(filters // 8, activation='relu', name='decoder_stage{}b_se_dense1'.format(i))(w)\n",
        "            w = Dense(filters, activation='sigmoid', name='decoder_stage{}b_se_dense2'.format(i))(w)\n",
        "            x = Multiply(name='decoder_stage{}b_se_mult'.format(i))([x, w])\n",
        "\n",
        "    task1 = Conv2D(filters=1, kernel_size=(3, 3), padding='same', kernel_initializer='glorot_uniform', name='final_conv_mask')(x)\n",
        "    task1 = Activation('sigmoid', name='final_activation_mask')(task1)\n",
        "\n",
        "    # prepare for Multitask Learning\n",
        "    if predict_contour:\n",
        "        task2 = Conv2D(filters=1, kernel_size=(3, 3), padding='same', kernel_initializer='glorot_uniform', name='final_conv_contour')(x)\n",
        "        task2 = Activation('sigmoid', name='final_activation_contour')(task2)\n",
        "    if predict_distance:\n",
        "        task3 = Conv2D(filters=1, kernel_size=(3, 3), padding='same', kernel_initializer='glorot_uniform', name='final_conv_distance')(x)\n",
        "        task3 = Activation('linear', name='final_activation_distance')(task3)\n",
        "\n",
        "    if predict_contour and predict_distance:\n",
        "        output = [task1, task2, task3]\n",
        "    elif predict_contour:\n",
        "        output = [task1, task2]\n",
        "    elif predict_distance:\n",
        "        output = [task1, task3]\n",
        "    else:\n",
        "        output = task1\n",
        "\n",
        "    model = tf.keras.models.Model(backbone.input, output)\n",
        "\n",
        "    # freeze encoder weights if requested\n",
        "    if encoder_freeze:\n",
        "        for layer in backbone.layers:\n",
        "            if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "                layer.trainable = False\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dIbRPFzjmV85",
        "colab": {}
      },
      "source": [
        "generator = RoadNet(backbone_name='seresnext101', predict_contour=False, aspp=False, se=False) # see not learning, aspp no improvement\n",
        "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U1N1_obwtdQH",
        "colab": {}
      },
      "source": [
        "gen_output = generator(inp[tf.newaxis,...], training=False)\n",
        "print(gen_output[0,...].shape)\n",
        "plt.imshow(tf.reshape(gen_output[0,...], (512,512))/255.0, cmap='Greys_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "90BIcCKcDMxz",
        "colab": {}
      },
      "source": [
        "\n",
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "  kld = 0 # save computation # tf.reduce_mean(tf.keras.losses.kullback_leibler_divergence(tf.ones_like(disc_generated_output), disc_generated_output))\n",
        "\n",
        "  # mean absolute error\n",
        "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "  l2_loss = 0 # save computation # tf.reduce_mean((target - gen_output)*(target - gen_output))\n",
        "\n",
        "  total_gen_loss = gan_loss + (50 * l1_loss) #+ kld #+ l2_loss\n",
        "\n",
        "  return total_gen_loss, gan_loss, l1_loss, l2_loss, kld"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ll6aNeQx8b4v",
        "colab": {}
      },
      "source": [
        "def Discriminator():\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  inp = tf.keras.layers.Input(shape=[512, 512, 3], name='input_image')\n",
        "  target = tf.keras.layers.Input(shape=[512, 512, 1], name='target_image')\n",
        "\n",
        "  x = tf.keras.layers.concatenate([inp, target]) # (bs, 256, 256, channels*2)\n",
        "\n",
        "  down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
        "  down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
        "  down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
        "\n",
        "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
        "  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
        "                                kernel_initializer=initializer,\n",
        "                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
        "  # add more layers if the discriminator needs to be stronger\n",
        "  #conv2 = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
        "  #                              kernel_initializer=initializer,\n",
        "  #                              use_bias=False)(conv) # (bs, 31, 31, 512)\n",
        "\n",
        "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
        "\n",
        "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
        "\n",
        "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
        "\n",
        "  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
        "                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inp, target], outputs=last)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YHoUui4om-Ev",
        "colab": {}
      },
      "source": [
        "discriminator = Discriminator()\n",
        "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gDkA05NE6QMs",
        "colab": {}
      },
      "source": [
        "disc_out = discriminator([inp[tf.newaxis,...], gen_output], training=False)\n",
        "plt.imshow(disc_out[0,...,-1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q1Xbz5OaLj5C",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wkMNfBWlT-PV",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "  return total_disc_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0FMYgY_mPfTi"
      },
      "source": [
        "## Define the Optimizers and Checkpoint-saver\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lbHFNexF0x6O",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(2e-3, beta_1=0.9)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-7, beta_1=0.6) # low learning rate to avoid it beating the generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WJnftd5sQsv6",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints_new6'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "## Generate Images\n",
        "\n",
        "Write a function to plot some images during training.\n",
        "\n",
        "* We pass images from the test dataset to the generator.\n",
        "* The generator will then translate the input image into the output.\n",
        "* Last step is to plot the predictions and **voila!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rb0QQFHF-JfS"
      },
      "source": [
        "Note: The `training=True` is intentional here since\n",
        "we want the batch statistics while running the model\n",
        "on the test dataset. If we use training=False, we will get\n",
        "the accumulated statistics learned from the training dataset\n",
        "(which we don't want)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RmdVsmvhPxyy",
        "colab": {}
      },
      "source": [
        "def generate_images(model, test_input, tar):\n",
        "  print(test_input.shape)\n",
        "  print(\"generate images\")\n",
        "  prediction = model(test_input, training=True)\n",
        "  plt.figure(figsize=(15,15))\n",
        "\n",
        "  display_list = [test_input[0], tar[0], prediction[0]]\n",
        "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        "  for i in range(3):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.title(title[i])\n",
        "    # getting the pixel values between [0, 1] to plot it.\n",
        "    denorm = display_list[i] * 0.5 + 0.5\n",
        "    if(denorm.shape[2] == 1):\n",
        "      plt.imshow(tf.reshape(denorm, (512,512))/255.0, cmap='Greys_r')\n",
        "    else:\n",
        "      plt.imshow(denorm)\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK2_HarUt3xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for example_input, example_target in train_dataset.take(3):\n",
        "  print(example_input.shape)\n",
        "  print(example_target.shape)\n",
        "  generate_images(generator, example_input, example_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Fc4NzT-DgEx",
        "colab": {}
      },
      "source": [
        "for example_input, example_target in test_dataset.take(10):\n",
        "  generate_images(generator, example_input, example_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xNNMDBNH12q-",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "log_dir=\"logs/\"\n",
        "\n",
        "summary_writer = tf.summary.create_file_writer(\n",
        "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC63RcgxNK1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsSk8MJzXpEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs #alternatively run it on the command line"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KBKUV2sKXDbY",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(input_image, target, epoch):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    gen_output = generator(input_image, training=True)\n",
        "\n",
        "    disc_real_output = discriminator([input_image, target], training=True)\n",
        "    disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
        "\n",
        "    gen_total_loss, gen_gan_loss, gen_l1_loss, gen_l2_loss, gen_kld_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "  generator_gradients = gen_tape.gradient(gen_total_loss,\n",
        "                                          generator.trainable_variables)\n",
        "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                               discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                          generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                              discriminator.trainable_variables))\n",
        "\n",
        "  with summary_writer.as_default():\n",
        "    tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_l2_loss', gen_l2_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_kld_loss', gen_kld_loss, step=epoch)\n",
        "    tf.summary.scalar('disc_loss', disc_loss, step=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2M7LmLtGEMQJ",
        "colab": {}
      },
      "source": [
        "def fit(train_ds, start_epoch, epochs, test_ds):\n",
        "  for epoch in range(start_epoch, epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "    for example_input, example_target in test_ds.take(1):\n",
        "      generate_images(generator, example_input, example_target)\n",
        "    print(\"Epoch: \", epoch)\n",
        "\n",
        "    # Train\n",
        "    for n, (input_image, target) in train_ds.enumerate():\n",
        "      print('.', end='')\n",
        "      if (n+1) % 100 == 0:\n",
        "        print()\n",
        "      train_step(input_image, target, epoch)\n",
        "    print()\n",
        "\n",
        "    # saving (checkpoint) the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
        "                                                        time.time()-start))\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvvf8FzwAr_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "continueTraining = False\n",
        "if(continueTraining):\n",
        "  checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir)) # continue training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a1zZmKmvOH85",
        "colab": {}
      },
      "source": [
        "fit(train_dataset, 0, 60, test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kz80bY3aQ1VZ"
      },
      "source": [
        "## Restore the latest checkpoint and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HSSm4kfvJiqv",
        "colab": {}
      },
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4t4x69adQ5xb",
        "colab": {}
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1RGysMU_BZhx"
      },
      "source": [
        "## Generate using test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KUgSnmy2nqSP",
        "colab": {}
      },
      "source": [
        "# Run the trained model on a few examples from the test dataset\n",
        "for inp, tar in test_dataset.take(5):\n",
        "  generate_images(generator, inp, tar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_Kq_Uaz2v7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_test_images(image_file):\n",
        "  print(\"load image test\")\n",
        "  print(image_file)\n",
        "  input_image = load(image_file)\n",
        "  print(input_image.shape)\n",
        "  input_image = (input_image / 127.5) - 1\n",
        "  return input_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZZ8HOVk2E2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_test_images = \"/home/jonathan/CIL-street/data/test_images/\"\n",
        "dataset_test_images_names = tf.data.Dataset.list_files(PATH_test_images+'*.png', shuffle=False)\n",
        "print(sum(1 for _ in dataset_test_images_names)) # should be 94\n",
        "dataset_test_images = dataset_test_images_names.map(load_test_images)\n",
        "dataset_test_images = dataset_test_images.batch(BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a1sIEKT1xBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import cv2\n",
        "\n",
        "for ind, (input_image, filename) in enumerate(zip(dataset_test_images.take(94), dataset_test_images_names.take(94))):\n",
        "  print(filename)\n",
        "  filename = filename.numpy()\n",
        "  filename = os.path.basename(str(filename)).split('.')[0]+'.png'\n",
        "\n",
        "  input_image0 = tf.image.crop_to_bounding_box(\n",
        "    input_image, 0, 0, 400, 400\n",
        "    )\n",
        "  input_image1 = tf.image.crop_to_bounding_box(\n",
        "    input_image, 208, 0, 400, 400\n",
        "    )\n",
        "  input_image2 = tf.image.crop_to_bounding_box(\n",
        "    input_image, 0, 208, 400, 400\n",
        "    )\n",
        "  input_image3 = tf.image.crop_to_bounding_box(\n",
        "    input_image, 208, 208, 400, 400\n",
        "    )\n",
        "  \n",
        "  patched = numpy.zeros((608,608,3))\n",
        "  patches = []\n",
        "  for input in [input_image0, input_image1, input_image2, input_image3]:\n",
        "    input = tf.image.resize(input, [512, 512],\n",
        "                                  method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "    print(filename)\n",
        "    prediction = generator(input, training=True)\n",
        "    plt.figure(figsize=(15,15))\n",
        "\n",
        "    title = ['Input Image', 'Predicted Image']\n",
        "    input0 = input[0] * 0.5 + 0.5\n",
        "    prediction0 = prediction[0] * 0.5 + 0.5\n",
        "    prediction0 = tf.image.resize(prediction0, (400, 400))\n",
        "    combined = prediction0\n",
        "\n",
        "    plt.subplot(1, 6, 1)\n",
        "    plt.title(title[0])\n",
        "    plt.imshow(input0)\n",
        "    plt.subplot(1, 6, 2)\n",
        "    plt.imshow(tf.reshape(prediction0, (400,400)), cmap='Greys_r')\n",
        "\n",
        "    for i in range(2, 5):\n",
        "      input_rot = tf.image.rot90(\n",
        "        input, k=(i-1)\n",
        "      )\n",
        "      prediction = generator(input_rot, training=True) # seems no difference if training or not\n",
        "      plt.subplot(1, 6, i+1)\n",
        "      pred_norm = prediction[0] * 0.5 + 0.5\n",
        "      pred_norm = tf.image.rot90(\n",
        "        pred_norm, k=-(i-1)\n",
        "      )\n",
        "      pred_norm = tf.image.resize(pred_norm, (400, 400))\n",
        "      plt.imshow(tf.reshape(pred_norm, (400,400)), cmap='Greys_r')\n",
        "      combined += pred_norm\n",
        "\n",
        "    plt.subplot(1, 6, 6)\n",
        "    plt.imshow(tf.reshape(combined, (400,400)), cmap='Greys_r')\n",
        "    patches.append(combined)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  patches[0] = tf.image.grayscale_to_rgb(patches[0] - 2)\n",
        "  patches[1] = tf.image.grayscale_to_rgb(patches[1] - 2)\n",
        "  patches[2] = tf.image.grayscale_to_rgb(patches[2] - 2)\n",
        "  patches[3] = tf.image.grayscale_to_rgb(patches[3] - 2)\n",
        "  patched[0:400, 0:400] += tf.image.resize(patches[0], [400, 400], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR) \n",
        "  patched[208:608, 0:400] += tf.image.resize(patches[1], [400, 400], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR) \n",
        "  patched[0:400, 208:608] += tf.image.resize(patches[2], [400, 400], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR) \n",
        "  patched[208:608, 208:608] += tf.image.resize(patches[3], [400, 400], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR) \n",
        "  patched[208:400, 0:208] /= 2 # center top\n",
        "  patched[208:400, 400:608] /= 2 # center bottom\n",
        "  patched[0:208, 208:400] /= 2 # center left\n",
        "  patched[400:608, 208:400] /= 2 # center right\n",
        "  patched[208:400, 208:400] /= 4\n",
        "\n",
        "  plt.imshow(input_image[0] * 0.5 + 0.5)\n",
        "  plt.show()\n",
        "\n",
        "  patched = tf.clip_by_value(\n",
        "    patched, 0, 1\n",
        "  )\n",
        "\n",
        "  # another test\n",
        "  # erode dilate\n",
        "  kernel = numpy.ones((10,10),numpy.uint8)\n",
        "  patched = patched.numpy()\n",
        "  #patched = cv2.morphologyEx(patched, cv2.MORPH_OPEN, kernel)\n",
        "  ret, patched = cv2.threshold(patched,0.25,1.0,cv2.THRESH_BINARY)\n",
        "  #patched = cv2.morphologyEx(patched, cv2.MORPH_CLOSE, kernel)\n",
        "  #patched = cv2.morphologyEx(patched, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "  plt.imshow(patched)\n",
        "  plt.show()\n",
        "\n",
        "  pred_uint = tf.image.convert_image_dtype(patched, tf.uint16)\n",
        "  enc = tf.image.encode_png(pred_uint)\n",
        "  fname = tf.constant(\"/home/jonathan/cil_pix2pix/\"+filename)\n",
        "  fwrite = tf.io.write_file(fname, enc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL0TamjbzY7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alternative but worse results\n",
        "\n",
        "'''\n",
        "import numpy\n",
        "for ind, (input_image, filename) in enumerate(zip(dataset_test_images.take(94), dataset_test_images_names.take(94))):\n",
        "  print(filename)\n",
        "  filename = filename.numpy()\n",
        "  filename = os.path.basename(str(filename)).split('.')[0]+'.png'\n",
        "\n",
        "  input = tf.image.resize(input_image, [512, 512],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "  print(filename)\n",
        "  prediction = generator(input, training=False)\n",
        "  plt.figure(figsize=(15,15))\n",
        "\n",
        "  title = ['Input Image', 'Predicted Image']\n",
        "  input0 = input[0] * 0.5 + 0.5\n",
        "  prediction0 = prediction[0] * 0.5 + 0.5\n",
        "  prediction0 = tf.image.resize(prediction0, (608, 608))\n",
        "  combined = prediction0\n",
        "\n",
        "  plt.subplot(1, 6, 1)\n",
        "  plt.title(title[0])\n",
        "  plt.imshow(input0)\n",
        "  plt.subplot(1, 6, 2)\n",
        "  plt.imshow(tf.reshape(prediction0, (608,608)), cmap='Greys_r')\n",
        "\n",
        "  for i in range(2, 5):\n",
        "    input_rot = tf.image.rot90(\n",
        "      input, k=(i-1)\n",
        "    )\n",
        "    prediction = generator(input_rot, training=False)\n",
        "    plt.subplot(1, 6, i+1)\n",
        "    pred_norm = prediction[0] * 0.5 + 0.5\n",
        "    pred_norm = tf.image.rot90(\n",
        "      pred_norm, k=-(i-1)\n",
        "    )\n",
        "    pred_norm = tf.image.resize(pred_norm, (608, 608))\n",
        "    plt.imshow(tf.reshape(pred_norm, (608,608)), cmap='Greys_r')\n",
        "    combined += pred_norm\n",
        "\n",
        "  plt.subplot(1, 6, 6)\n",
        "  plt.imshow(tf.reshape(combined, (608,608)), cmap='Greys_r')\n",
        "  plt.show()\n",
        "\n",
        "  combined = tf.image.grayscale_to_rgb(combined - 2)\n",
        "  patched = tf.image.resize(combined*255, [608, 608], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR) \n",
        "  \n",
        "  plt.imshow(input_image[0] * 0.5 + 0.5)\n",
        "  plt.show()\n",
        "\n",
        "  patched = tf.clip_by_value(\n",
        "    patched, 0, 1\n",
        "  )\n",
        "  plt.imshow(patched)\n",
        "  plt.show()\n",
        "\n",
        "  pred_uint = tf.image.convert_image_dtype(patched, tf.uint16)\n",
        "  enc = tf.image.encode_png(pred_uint)\n",
        "  fname = tf.constant(\"/home/jonathan/cil_pix2pix/\"+filename)\n",
        "  fwrite = tf.io.write_file(fname, enc)\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF5CmAk310eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}